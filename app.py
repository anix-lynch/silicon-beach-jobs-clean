#!/usr/bin/env python3
"""
Silicon Beach Tech Companies
Interactive map of LA tech companies with commute analysis
Built with DuckDB, Streamlit, and Folium
"""

import streamlit as st
import pandas as pd
import folium
from streamlit_folium import folium_static
import duckdb
from datetime import datetime

# ==============================================================================
# CONFIG
# ==============================================================================

st.set_page_config(
    page_title="Silicon Beach Companies",
    page_icon="üèñÔ∏è",
    layout="wide"
)

DUCKDB_FILE = "data/silicon_beach.duckdb"

# ==============================================================================
# DATABASE CONNECTION
# ==============================================================================

@st.cache_resource(show_spinner=False)
def get_duckdb_connection():
    """Create DuckDB connection and ensure tables exist"""
    conn = duckdb.connect(DUCKDB_FILE, read_only=False)
    
    # Check if jobs_cleaned exists (table or view), if not create from CSV or empty table
    try:
        # Try to query it - works for both tables and views
        conn.execute("SELECT COUNT(*) FROM jobs_cleaned").fetchone()
    except Exception as e:
        # Table/view doesn't exist, try to create from CSV files
        import os
        csv_files = [
            "data/la_vcs_20251111_083756_enriched.csv",
            "data/builtinla_mcp_20251111_085045.csv",
        ]
        
        for csv_file in csv_files:
            if os.path.exists(csv_file):
                try:
                    df = pd.read_csv(csv_file)
                    # Standardize column names
                    df.columns = df.columns.str.lower()
                    # Create table from first CSV found
                    conn.execute("CREATE TABLE IF NOT EXISTS jobs_cleaned AS SELECT * FROM df")
                    break
                except Exception as e:
                    # Can't use st.warning in cache_resource, just continue
                    pass
        
        # If still no table, create empty one with expected schema
        try:
            conn.execute("SELECT COUNT(*) FROM jobs_cleaned").fetchone()
        except:
            # Create empty table with all possible columns
            conn.execute("""
                CREATE TABLE IF NOT EXISTS jobs_cleaned (
                    type VARCHAR,
                    company VARCHAR,
                    title VARCHAR,
                    area VARCHAR,
                    location VARCHAR,
                    address VARCHAR,
                    stage VARCHAR,
                    focus VARCHAR,
                    transit_duration VARCHAR,
                    transit_routes VARCHAR,
                    transit_changes INTEGER,
                    commute_rating VARCHAR,
                    commute_score INTEGER,
                    google_maps_link VARCHAR,
                    career_url VARCHAR,
                    job_url VARCHAR,
                    linkedin_search VARCHAR,
                    contact_name VARCHAR,
                    contact_email VARCHAR,
                    closest_metro VARCHAR
                )
            """)
        
        # Also ensure referral_paths table exists
        try:
            conn.execute("SELECT COUNT(*) FROM referral_paths").fetchone()
        except:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS referral_paths (
                    company VARCHAR,
                    target_person VARCHAR,
                    target_title VARCHAR,
                    connector_name VARCHAR,
                    connector_relationship VARCHAR,
                    connection_tier INTEGER,
                    notes VARCHAR,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
    
    return conn

def add_referral(company, target_person, target_title, connector_name, relationship, tier, notes):
    """Add a referral path to DuckDB"""
    conn = get_duckdb_connection()
    conn.execute("""
        INSERT INTO referral_paths 
        (company, target_person, target_title, connector_name, 
         connector_relationship, connection_tier, notes)
        VALUES (?, ?, ?, ?, ?, ?, ?)
    """, [company, target_person, target_title, connector_name, relationship, tier, notes])

def get_referrals(company=None):
    """Get all referral paths from DuckDB"""
    conn = get_duckdb_connection()
    if company:
        df = conn.execute("""
            SELECT * FROM referral_paths 
            WHERE company = ? 
            ORDER BY created_at DESC
        """, [company]).df()
    else:
        df = conn.execute("""
            SELECT * FROM referral_paths 
            ORDER BY created_at DESC
        """).df()
    return df

# ==============================================================================
# LOAD DATA
# ==============================================================================

@st.cache_data(ttl=300, show_spinner=False)
def load_jobs():
    """Load job and VC data from DuckDB"""
    conn = get_duckdb_connection()
    
    # First, check what columns actually exist
    try:
        columns_info = conn.execute("DESCRIBE jobs_cleaned").fetchall()
        available_columns = [col[0].lower() for col in columns_info]
    except:
        # If describe fails, try to get columns from a sample query
        try:
            sample = conn.execute("SELECT * FROM jobs_cleaned LIMIT 1").df()
            available_columns = [col.lower() for col in sample.columns]
        except:
            # Table doesn't exist or is empty, return empty dataframe
            return pd.DataFrame()
    
    # Build SELECT with only columns that exist
    select_cols = []
    column_map = {
        'type': "COALESCE(type, 'JOB') as type",
        'company': 'company',
        'title': 'title',
        'area': 'area',
        'location': 'location',
        'address': 'address',
        'stage': 'stage',
        'focus': 'focus',
        'transit_duration': 'transit_duration',
        'transit_routes': 'transit_routes',
        'transit_changes': 'transit_changes',
        'commute_rating': 'commute_rating',
        'commute_score': 'commute_score',
        'google_maps_link': 'google_maps_link',
        'career_url': 'career_url',
        'job_url': 'job_url',
        'linkedin_search': 'linkedin_search',
        'contact_name': 'contact_name',
        'contact_email': 'contact_email',
        'closest_metro': 'closest_metro'
    }
    
    for col_name, col_expr in column_map.items():
        if col_name in available_columns:
            select_cols.append(col_expr)
        else:
            # Add NULL for missing columns
            if 'as' in col_expr:
                select_cols.append(f"NULL as {col_expr.split(' as ')[1]}")
            else:
                select_cols.append(f"NULL as {col_name}")
    
    query = f"""
        SELECT {', '.join(select_cols)}
        FROM jobs_cleaned
        ORDER BY COALESCE(type, 'JOB') DESC, COALESCE(commute_score, 0) DESC
    """
    
    try:
        df = conn.execute(query).df()
        # Ensure all expected columns exist (fill with None if missing)
        expected_cols = ['type', 'company', 'title', 'area', 'location', 'address', 
                       'stage', 'focus', 'transit_duration', 'transit_routes', 
                       'transit_changes', 'commute_rating', 'commute_score',
                       'google_maps_link', 'career_url', 'job_url', 'linkedin_search',
                       'contact_name', 'contact_email', 'closest_metro']
        for col in expected_cols:
            if col not in df.columns:
                df[col] = None
        return df
    except Exception as e:
        st.error(f"Error loading jobs: {str(e)}")
        return pd.DataFrame()

# ==============================================================================
# GEOCODING
# ==============================================================================

AREA_COORDS = {
    "Culver City": (34.0211, -118.3965),
    "Santa Monica": (34.0195, -118.4912),
    "Playa Vista": (33.9777, -118.4198),
    "West LA": (34.0522, -118.4437),
    "Downtown LA": (34.0407, -118.2468),
    "Hollywood": (34.0928, -118.3287),
    "West Hollywood": (34.0900, -118.3617),
    "Hawthorne": (33.9164, -118.3526),
    "El Segundo": (33.9192, -118.4165),
}

def get_coords(area):
    return AREA_COORDS.get(area, (34.0211, -118.3965))

# ==============================================================================
# MAP
# ==============================================================================

def create_map(df, selected_commute="All", show_jobs=True, show_vcs=True):
    if selected_commute != "All":
        # Handle NaN values in commute_rating
        df = df[df['commute_rating'].notna() & (df['commute_rating'].astype(str).str.contains(selected_commute))]
    
    # Filter by type - handle NaN safely
    if not show_jobs:
        # Only show VCs
        df = df[df['type'].notna() & (df['type'].astype(str).str.upper() == 'VC')]
    if not show_vcs:
        # Hide VCs (show jobs and NaN types)
        df = df[df['type'].isna() | (df['type'].astype(str).str.upper() != 'VC')]
    
    m = folium.Map(
        location=[34.0211, -118.3965],
        zoom_start=11,
        tiles="OpenStreetMap"
    )
    
    folium.Marker(
        [34.0211, -118.3965],
        popup="üè† Your Home<br>Culver City",
        icon=folium.Icon(color="red", icon="home", prefix='fa'),
        tooltip="Your Location"
    ).add_to(m)
    
    for idx, row in df.iterrows():
        coords = get_coords(row.get('area', 'Culver City'))
        
        # Different colors for VCs vs Jobs - handle NaN/None safely
        row_type = row.get('type')
        # Ensure is_vc is always a boolean, never pandas NA
        try:
            is_vc = bool(pd.notna(row_type) and str(row_type).upper() == 'VC')
        except:
            is_vc = False
        
        if is_vc:
            # Orange pins for VCs
            commute_score = row.get('commute_score', 0)
            if pd.notna(commute_score) and commute_score >= 100:
                color = 'orange'
                icon = 'briefcase'
            elif pd.notna(commute_score) and commute_score >= 75:
                color = 'beige'
                icon = 'briefcase'
            else:
                color = 'lightgray'
                icon = 'briefcase'
        else:
            # Green pins for Jobs
            commute_score = row.get('commute_score', 0)
            if pd.notna(commute_score) and commute_score >= 100:
                color = 'green'
                icon = 'star'
            elif row['commute_score'] >= 75:
                color = 'lightgreen'
                icon = 'star-half'
            else:
                color = 'gray'
                icon = 'circle'
        
        # Safe value extraction for popup
        company = row.get('company', 'Unknown')
        area = row.get('area', 'N/A')
        transit_duration = row.get('transit_duration', 'N/A')
        transit_routes = row.get('transit_routes', 'N/A')
        commute_rating = row.get('commute_rating', 'N/A')
        closest_metro = row.get('closest_metro', 'N/A')
        career_url = row.get('career_url', '#')
        google_maps_link = row.get('google_maps_link', '#')
        job_url = row.get('job_url', row.get('career_url', '#'))
        linkedin_search = row.get('linkedin_search', '#')
        stage = row.get('stage', 'N/A')
        focus = row.get('focus', 'N/A')
        
        if is_vc:
            popup_html = f"""
            <div style="width: 300px">
                <h4>üíº {company}</h4>
                <b>Type:</b> VC Firm<br>
                <b>Stage:</b> {stage}<br>
                <b>Focus:</b> {focus}<br>
                <b>Area:</b> {area}<br>
                <b>Commute:</b> {transit_duration}<br>
                <b>Routes:</b> {transit_routes}<br>
                <b>Rating:</b> {commute_rating}<br>
                <br>
                <a href="{career_url}" target="_blank">üîó Search Careers</a><br>
                <a href="{google_maps_link}" target="_blank">üó∫Ô∏è Get Directions</a><br>
                <a href="{linkedin_search}" target="_blank">üîç Find Partners</a>
            </div>
            """
        else:
            popup_html = f"""
            <div style="width: 300px">
                <h4>üíª {company}</h4>
                <b>Type:</b> Tech Job<br>
                <b>Area:</b> {area}<br>
                <b>Commute:</b> {transit_duration}<br>
                <b>Routes:</b> {transit_routes}<br>
                <b>Rating:</b> {commute_rating}<br>
                <b>Metro:</b> {closest_metro}<br>
                <br>
                <a href="{career_url}" target="_blank">üîó Career Page</a><br>
                <a href="{google_maps_link}" target="_blank">üó∫Ô∏è Get Directions</a><br>
                <a href="{job_url}" target="_blank">üëî Find Hiring Manager</a>
            </div>
            """
        
        folium.Marker(
            coords,
            popup=folium.Popup(popup_html, max_width=300),
            icon=folium.Icon(color=color, icon=icon, prefix='fa'),
            tooltip=f"{'üíº' if is_vc else 'üíª'} {row.get('company', 'Unknown')} - {row.get('transit_duration', 'N/A')}"
        ).add_to(m)
    
    return m

# ==============================================================================
# MAIN APP
# ==============================================================================

def main():
    st.title("üèñÔ∏è Silicon Beach Tech Companies")
    st.markdown("*Tech companies in LA's Silicon Beach area*")
    st.markdown("---")
    
    # Clear cache button for debugging
    if st.sidebar.button("üîÑ Clear Cache"):
        st.cache_data.clear()
        st.cache_resource.clear()
        st.rerun()
    
    df = load_jobs()
    
    # Sidebar
    st.sidebar.header("üîç Filters")
    
    # Type filter
    show_jobs = st.sidebar.checkbox("üíª Show Tech Jobs", value=True)
    show_vcs = st.sidebar.checkbox("üíº Show VC Firms", value=True)
    
    commute_filter = st.sidebar.selectbox(
        "Commute Rating",
        ["All", "Excellent", "Good", "Acceptable"]
    )
    
    area_filter = st.sidebar.multiselect(
        "Areas",
        options=sorted(df['area'].unique().tolist()),
        default=df['area'].unique().tolist()
    )
    
    min_score = st.sidebar.slider(
        "Minimum Commute Score",
        min_value=0,
        max_value=100,
        value=50
    )
    
    filtered_df = df[
        (df['area'].isin(area_filter)) &
        (df['commute_score'] >= min_score)
    ]
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üìç Job Map")
        
        # Count jobs and VCs - handle NaN safely
        if 'type' in filtered_df.columns:
            # Convert to string first to avoid AttributeError
            type_str = filtered_df['type'].astype(str)
            num_jobs = len(filtered_df[filtered_df['type'].isna() | (type_str.str.upper() != 'VC')])
            num_vcs = len(filtered_df[filtered_df['type'].notna() & (type_str.str.upper() == 'VC')])
        else:
            num_jobs = len(filtered_df)
            num_vcs = 0
        
        st.markdown(f"**{num_jobs} tech jobs | {num_vcs} VC firms** | üü¢ Green = Jobs | üü† Orange = VCs")
        
        job_map = create_map(filtered_df, commute_filter, show_jobs, show_vcs)
        folium_static(job_map, width=800, height=600)
    
    with col2:
        st.header("üìä Summary")
        
        excellent = len(df[df['commute_score'] >= 100])
        good = len(df[df['commute_score'] >= 75]) - excellent
        
        st.metric("üü¢ Excellent Commute", excellent)
        st.metric("üü† Good Commute", good)
        st.metric("üìç Total Companies", len(df))
        
        st.markdown("---")
        st.subheader("üèÜ Top Targets")
        
        for idx, row in filtered_df.head(6).iterrows():
            with st.expander(f"**{row['company']}** - {row['transit_duration']}"):
                st.write(f"**Area:** {row['area']}")
                st.write(f"**Route:** {row['transit_routes']}")
                st.write(f"**Score:** {row['commute_score']}/100")
                if row['contact_name']:
                    st.write(f"**Contact:** {row['contact_name']}")
                if row['contact_email']:
                    st.write(f"**Email:** {row['contact_email']}")
                st.markdown(f"[Career Page]({row['career_url']})")
                st.markdown(f"[Find Hiring Manager]({row['job_url']})")
    
    # Network Tracker
    st.markdown("---")
    st.header("üîó Network Tracker")
    
    tab1, tab2 = st.tabs(["‚ûï Add Referral Path", "üìã View Connections"])
    
    with tab1:
        st.subheader("Record a Warm Intro Path")
        
        col_a, col_b = st.columns(2)
        
        with col_a:
            target_company = st.selectbox("Target Company", options=sorted(df['company'].tolist()))
            target_person = st.text_input("Hiring Manager Name", placeholder="e.g., David Shi")
            target_title = st.text_input("Their Title", placeholder="e.g., Data Engineering Manager")
        
        with col_b:
            connector_name = st.text_input("Your Connection", placeholder="e.g., Elise Sha")
            relationship = st.text_input("How do you know them?", placeholder="e.g., Chicago Booth Alum")
            tier = st.select_slider("Connection Tier", options=[1, 2, 3], value=2)
        
        notes = st.text_area("Notes", placeholder="e.g., Met at Booth mixer 2023")
        
        if st.button("üíæ Save Referral Path"):
            if target_person and connector_name:
                add_referral(target_company, target_person, target_title, connector_name, relationship, tier, notes)
                st.success(f"‚úÖ Saved: {connector_name} ‚Üí {target_person} at {target_company}")
                st.cache_data.clear()
                st.rerun()
            else:
                st.error("Please fill in at least Target Person and Connector Name")
    
    with tab2:
        st.subheader("Your Network Connections")
        
        company_filter = st.selectbox(
            "Filter by Company (optional)",
            options=["All"] + sorted(df['company'].tolist())
        )
        
        referrals = get_referrals() if company_filter == "All" else get_referrals(company_filter)
        
        if len(referrals) == 0:
            st.info("No referral paths recorded yet. Add your first one above!")
        else:
            for idx, ref in referrals.iterrows():
                with st.expander(f"**{ref['company']}** - {ref['target_person']} (Tier {ref['connection_tier']})"):
                    st.write(f"**üéØ Target:** {ref['target_person']}")
                    st.write(f"**üíº Title:** {ref['target_title']}")
                    st.write(f"**üîó Via:** {ref['connector_name']}")
                    st.write(f"**ü§ù Relationship:** {ref['connector_relationship']}")
                    st.write(f"**üìù Notes:** {ref['notes']}")
                    st.caption(f"Added: {ref['created_at']}")
    
    # Table
    st.markdown("---")
    st.header("üìã All Companies")
    
    display_df = filtered_df[['company', 'area', 'transit_duration', 'transit_routes', 'commute_rating', 'commute_score']].copy()
    
    st.dataframe(
        display_df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "commute_score": st.column_config.ProgressColumn(
                "Score",
                format="%d",
                min_value=0,
                max_value=100,
            ),
        }
    )
    
    st.markdown("---")
    st.caption("üí° Data stored in local DuckDB | Free forever | Deploy to Streamlit Cloud")

if __name__ == "__main__":
    main()


